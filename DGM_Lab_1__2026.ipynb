{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz0vwRWeUnvo"
      },
      "source": [
        "# Авторегрессионные линейные модели для прогнозирования временных рядов: частотный и байесовский подходы\n",
        "\n",
        "## Цель работы\n",
        "\n",
        "Изучить и сравнить частотный и байесовский подходы к построению авторегрессионных моделей прогнозирования временных рядов.\n",
        "\n",
        "## Задачи\n",
        "\n",
        "1. Реализовать трансформер лаговых признаков для построения авторегрессионных моделей.\n",
        "2. Реализовать Ridge-регрессию с автоматическим подбором гиперпараметра регуляризации.\n",
        "3. Реализовать байесовскую линейную регрессию с использованием стохастического вариационного вывода (SVI).\n",
        "4. Разработать процедуру авторегрессионного прогнозирования для обеих моделей.\n",
        "5. Сравнить качество моделей по метрикам RMSE, MAE, R².\n",
        "6. Провести сравнительный анализ частотного и байесовского подходов: точность, оценка неопределённости, интерпретируемость."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vYSgpoT9NqY"
      },
      "source": [
        "## Теоретическое введение\n",
        "\n",
        "### 1. Авторегрессионные модели\n",
        "\n",
        "Авторегрессионная модель порядка $p$ — AR(p) — предполагает, что текущее значение временного ряда линейно зависит от $p$ предыдущих значений:\n",
        "\n",
        "$$y_t = \\sum_{i=1}^{p} w_i \\cdot y_{t-i} + \\varepsilon_t, \\quad \\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$$\n",
        "\n",
        "В обобщённом случае модель может включать дополнительные экзогенные признаки $\\mathbf{x}_t$ (температура, осадки и др.), что приводит к авторегрессионной модели с экзогенными переменными (ARX).\n",
        "\n",
        "**Порождающая интерпретация:** AR-модель задаёт факторизацию совместного распределения временного ряда:\n",
        "\n",
        "$$p(y_1, \\ldots, y_T) = \\prod_{t=1}^{T} p(y_t | y_{t-1}, \\ldots, y_{t-p})$$\n",
        "\n",
        "Это позволяет генерировать новые последовательности и оценивать неопределённость прогноза.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Классическая линейная регрессия с регуляризацией\n",
        "\n",
        "**Линейная регрессия** моделирует целевую переменную как линейную комбинацию признаков:\n",
        "\n",
        "$$\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b$$\n",
        "\n",
        "**Ridge-регрессия** (L2-регуляризация) решает проблему переобучения, добавляя штраф на норму весов:\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{w}) = \\underbrace{\\|\\mathbf{y} - \\mathbf{X}\\mathbf{w}\\|_2^2}_{\\text{MSE}} + \\underbrace{\\alpha\\|\\mathbf{w}\\|_2^2}_{\\text{регуляризация}} \\to \\min_{\\mathbf{w}}$$\n",
        "\n",
        "где $\\alpha > 0$ — коэффициент регуляризации, контролирующий компромисс между качеством подгонки и сложностью модели.\n",
        "\n",
        "**Аналитическое решение:**\n",
        "\n",
        "$$\\mathbf{w}^* = (\\mathbf{X}^\\top\\mathbf{X} + \\alpha\\mathbf{I})^{-1}\\mathbf{X}^\\top\\mathbf{y}$$\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Байесовская линейная регрессия\n",
        "\n",
        "Байесовский подход рассматривает веса как случайные величины с априорным распределением:\n",
        "\n",
        "- **Априор:** $p(\\mathbf{w}) = \\mathcal{N}(\\mathbf{0}, \\sigma_p^2\\mathbf{I})$ — веса сосредоточены около нуля\n",
        "- **Правдоподобие:** $p(y|\\mathbf{x}, \\mathbf{w}) = \\mathcal{N}(\\mathbf{w}^\\top\\mathbf{x} + b, \\sigma_n^2)$\n",
        "- **Апостериор:** $p(\\mathbf{w}|\\mathcal{D}) \\propto p(\\mathcal{D}|\\mathbf{w}) \\cdot p(\\mathbf{w})$\n",
        "\n",
        "**Преимущества:**\n",
        "\n",
        "- Естественная оценка неопределённости предсказаний.\n",
        "- Устойчивость к переобучению через априор.\n",
        "- Возможность инкрементального обучения.\n",
        "\n",
        "**Связь с Ridge:** при $\\alpha = \\sigma_n^2 / \\sigma_p^2$ MAP-оценка байесовской регрессии совпадает с решением Ridge.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Вариационный вывод\n",
        "\n",
        "Точный апостериор $p(\\mathbf{w}|\\mathcal{D})$ часто не вычислим аналитически. **Вариационный вывод** аппроксимирует его простым распределением $q_\\phi(\\mathbf{w})$.\n",
        "\n",
        "**Mean-Field приближение:**\n",
        "\n",
        "$$q_\\phi(\\mathbf{w}) = \\mathcal{N}(\\boldsymbol{\\mu}, \\text{diag}(\\boldsymbol{\\sigma}^2))$$\n",
        "\n",
        "Параметры $\\phi = \\{\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}\\}$ находятся максимизацией **ELBO** (Evidence Lower Bound):\n",
        "\n",
        "$$\\mathcal{L}(\\phi) = \\mathbb{E}_{q_\\phi}[\\log p(\\mathcal{D}|\\mathbf{w})] - D_{KL}(q_\\phi(\\mathbf{w}) \\| p(\\mathbf{w})) \\to \\max_\\phi$$\n",
        "\n",
        "- Первый член — ожидаемое правдоподобие данных.\n",
        "- Второй член — KL-дивергенция, штрафующая отклонение от априора.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Стохастический вариационный вывод (SVI)\n",
        "\n",
        "Для больших датасетов ELBO оптимизируется на **мини-батчах** с масштабированием:\n",
        "\n",
        "$$\\mathcal{L}(\\phi) \\approx \\frac{N}{|\\mathcal{B}|}\\sum_{i \\in \\mathcal{B}}\\mathbb{E}_{q_\\phi}[\\log p(y_i|\\mathbf{x}_i, \\mathbf{w})] - D_{KL}(q_\\phi \\| p)$$\n",
        "\n",
        "**Трюк репараметризации** позволяет вычислять градиенты через сэмплирование:\n",
        "\n",
        "$$\\mathbf{w} = \\boldsymbol{\\mu} + \\boldsymbol{\\sigma} \\odot \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$$\n",
        "\n",
        "Это делает $\\mathbf{w}$ детерминированной функцией параметров $\\phi$, что позволяет применять стандартное автодифференцирование.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Предсказание с оценкой неопределённости\n",
        "\n",
        "При предсказании сэмплируем веса из обученного апостериора:\n",
        "\n",
        "$$\\hat{y} = \\frac{1}{S}\\sum_{s=1}^{S}(\\mathbf{w}^{(s)\\top}\\mathbf{x} + b), \\quad \\mathbf{w}^{(s)} \\sim q_\\phi(\\mathbf{w})$$\n",
        "\n",
        "**Виды неопределённости:**\n",
        "\n",
        "- **Эпистемическая** (модельная) — из-за конечности данных, уменьшается с ростом выборки.\n",
        "- **Алеаторная** (шум данных) — неустранимая, связана с $\\sigma_n^2$.\n",
        "\n",
        "Полная неопределённость предсказания: $\\text{Var}[\\hat{y}] = \\text{Var}_{\\text{epistemic}} + \\sigma_n^2$\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Сравнение частотного и байесовского подходов\n",
        "\n",
        "| Критерий | Частотный (Ridge) | Байесовский (SVI) |\n",
        "|----------|-------------------|-------------------|\n",
        "| **Оценка параметров** | Точечная оценка $\\mathbf{w}^*$ | Распределение $q(\\mathbf{w})$ |\n",
        "| **Неопределённость** | Не оценивается напрямую | Естественная оценка через дисперсию |\n",
        "| **Вычислительная сложность** | Низкая (аналитическое решение) | Высокая (итеративная оптимизация) |\n",
        "| **Интерпретируемость** | Простая | Требует понимания вероятностных концепций |\n",
        "| **Регуляризация** | Явный гиперпараметр $\\alpha$ | Неявная через априор |\n",
        "| **Масштабируемость** | Отличная | Хорошая (через SVI) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAGuKBsQ7Pwb"
      },
      "source": [
        "## Импорт библиотек\n",
        "\n",
        "Загружаем необходимые модули: pandas/numpy для данных, torch для SVI,\n",
        "sklearn для пайплайнов и метрик, matplotlib для визуализации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Epr4nM-Ox2bm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Библиотеки успешно загружены\n"
          ]
        }
      ],
      "source": [
        "# === Стандартные библиотеки ===\n",
        "import warnings\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "# === Научные вычисления ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === Визуализация ===\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# === PyTorch ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# === Scikit-learn ===\n",
        "from sklearn import set_config as skl_set_config\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# === Загрузка данных ===\n",
        "import gdown\n",
        "\n",
        "# Настройки\n",
        "warnings.filterwarnings('ignore')\n",
        "skl_set_config(transform_output=\"pandas\")\n",
        "\n",
        "print('Библиотеки успешно загружены')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7QSU8Jk7Pwd"
      },
      "source": [
        "## Загрузка данных\n",
        "\n",
        "В работе анализируется датасет [Pakistan Weather Data (2014-2023)](https://www.kaggle.com/datasets/abdulwadood11220/pakistan-weather-data-2014-2023), который содержит информацию о погоде в Пакистане в разных городах. Для каждых даты и города имеется информация о максимальной и минимальной температурах, факта наличия дождя и величины солнечной радиации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLHVm4OZx2bn"
      },
      "outputs": [],
      "source": [
        "# Загрузка датасета\n",
        "!gdown 1SSXm1Yldoxb_je803ou1NKqVS-cHuDMp\n",
        "df_full = pd.read_csv(\"/content/weather.csv\")\n",
        "df_full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMS-KhbfCgDF"
      },
      "source": [
        "Посмотрим на характеристики датасета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asTMwIgNCfHA"
      },
      "outputs": [],
      "source": [
        "print(f'Загружено строк: {len(df_full)}')\n",
        "print(f'Столбцы: {list(df_full.columns)}')\n",
        "print(f'Города: {df_full[\"city\"].unique()[:5]}...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9JuSBSnExSC"
      },
      "source": [
        "Все дальнейшие исследования будем проводить только с погодой города `Rawalpindi`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3shp0OGE-Ka"
      },
      "outputs": [],
      "source": [
        "# Фильтрация по городу\n",
        "df = df_full[df_full['city'] == 'Rawalpindi'].copy()\n",
        "\n",
        "# Преобразование дат и сортировка\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
        "df = (\n",
        "    df.sort_values('date')\n",
        "    .reset_index(drop=True)\n",
        "    .set_index(\"date\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrBkbrAhD6rc"
      },
      "source": [
        "Посмотрим на поведение целевой переменной."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRWptCpPDq7H"
      },
      "outputs": [],
      "source": [
        "df[\"temp_max\"].plot(figsize=(20, 7), grid=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn7_xwnuFHyk"
      },
      "source": [
        "Проанализируем признаки датасета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY6C5pvNpXy7"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe3eTvnJFNTE"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJQmzKbd7Pwd"
      },
      "source": [
        "## Предобработка данных\n",
        "\n",
        "Бинаризуем признак `rain` по критерию того, был ли дождь в этот день."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umfS6MDex2bo"
      },
      "outputs": [],
      "source": [
        "# Бинаризация: был ли дождь (1) или нет (0)\n",
        "df['rain'] = (df['rain'] > 0).astype(float)\n",
        "\n",
        "# Выбор признаков для модели\n",
        "FEATURES = ['rain', 'solar_radiation', 'temp_max']\n",
        "TARGET = 'temp_max'\n",
        "\n",
        "df = df[FEATURES].dropna()\n",
        "print(f'Записей для Rawalpindi: {len(df)}')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSDUxDVn7Pwe"
      },
      "source": [
        "## Разбиение на train/val/test\n",
        "\n",
        "Для контроля качества обучения моделей и оценки предсказаний требуется разделить датасет на обущающую, валидационную и тестовую части. Для временных рядов стандартным является временнОе разбиение 70/15/15 с сохранением хронологии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjqB7xDib1d9"
      },
      "outputs": [],
      "source": [
        "# Гиперпараметр: глубина лагов (запаздывания по времени)\n",
        "N_LAGS = 2\n",
        "\n",
        "# Индексы для разбиения 70/15/15\n",
        "train_end = int(0.70 * len(df))\n",
        "val_end = int(0.85 * len(df))\n",
        "\n",
        "# Разбиение данных\n",
        "X_train = df[:train_end]\n",
        "y_train = df[['temp_max']][:train_end]\n",
        "\n",
        "X_val = df[train_end:val_end]\n",
        "y_val = df[['temp_max']][train_end:val_end]\n",
        "\n",
        "X_test = df[val_end:]\n",
        "y_test = df[['temp_max']][val_end:]\n",
        "\n",
        "# Даты для графиков\n",
        "dates_test = y_test.index.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HKWPYkj7Pwf"
      },
      "source": [
        "## Трансформер для лаговых признаков\n",
        "\n",
        "Создаёт признаки с задержкой (lag) для авторегрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjf9NvZggB58"
      },
      "outputs": [],
      "source": [
        "class LaggedFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Создаёт лаговые признаки для авторегрессионных моделей.\n",
        "\n",
        "    Attributes:\n",
        "        n_lags: Количество временных лагов.\n",
        "        feature_names_in_: Имена входных признаков.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_lags: int = 5) -> None:\n",
        "        \"\"\"Инициализация трансформера.\n",
        "\n",
        "        Args:\n",
        "            n_lags: Количество лагов для создания.\n",
        "        \"\"\"\n",
        "        self.n_lags = n_lags\n",
        "        self.feature_names_in_: Optional[List[str]] = None\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        X: Union[pd.DataFrame, np.ndarray],\n",
        "        y: Optional[np.ndarray] = None\n",
        "    ) -> 'LaggedFeaturesTransformer':\n",
        "        \"\"\"Запоминает названия колонок.\n",
        "\n",
        "        Args:\n",
        "            X: Входные данные.\n",
        "            y: Целевая переменная (не используется).\n",
        "\n",
        "        Returns:\n",
        "            self: Обученный трансформер.\n",
        "        \"\"\"\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        else:\n",
        "            # Генерируем имена для numpy array\n",
        "            n_features = X.shape[1]\n",
        "            self.feature_names_in_ = [\n",
        "                f\"feature_{i}\" for i in range(n_features)\n",
        "            ]\n",
        "        return self\n",
        "\n",
        "    def transform(\n",
        "        self,\n",
        "        X: Union[pd.DataFrame, np.ndarray]\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"Создаёт лаговые признаки.\n",
        "\n",
        "        Args:\n",
        "            X: Входные данные.\n",
        "\n",
        "        Returns:\n",
        "            DataFrame с лаговыми признаками.\n",
        "        \"\"\"\n",
        "        # Преобразуем в numpy для скорости\n",
        "        X_values = X.values if isinstance(X, pd.DataFrame) else X\n",
        "        n_samples, _ = X_values.shape\n",
        "\n",
        "        # Сборка лагов через срезы\n",
        "        lagged_arrays = []\n",
        "        for lag in range(1, self.n_lags + 1):\n",
        "            start = self.n_lags - lag\n",
        "            end = n_samples - lag\n",
        "            lagged_arrays.append(X_values[start:end])\n",
        "\n",
        "        X_transformed = np.hstack(lagged_arrays)\n",
        "\n",
        "        # Генерация имён колонок: feature_lag1, feature_lag2, ...\n",
        "        new_columns = [\n",
        "            f\"{feat}_lag{lag}\"\n",
        "            for lag in range(1, self.n_lags + 1)\n",
        "            for feat in self.feature_names_in_\n",
        "        ]\n",
        "\n",
        "        return pd.DataFrame(X_transformed, columns=new_columns)\n",
        "\n",
        "\n",
        "print('LaggedFeaturesTransformer создан')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_vjYxAx7Pwf"
      },
      "source": [
        "## Ridge-регрессия с кросс-валидацией\n",
        "\n",
        "Реализуем классическую регрессию в виде scikit-learn-эстиматора, обернув в него `Ridge`-регрессию с автоподбором гиперпараметра $L_2$-регуляризации $\\alpha$ с помощью `TimeSeriesSplit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMuiZaOTx2bp"
      },
      "outputs": [],
      "source": [
        "class RidgeRegressionCV(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"Ridge-регрессия с кросс-валидацией по временным рядам.\n",
        "\n",
        "    Attributes:\n",
        "        alphas: Список значений alpha для перебора.\n",
        "        n_splits: Число фолдов для TimeSeriesSplit.\n",
        "        best_model_: Лучшая обученная модель.\n",
        "        best_alpha_: Лучшее значение alpha.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        alphas: Optional[List[float]] = None,\n",
        "        n_splits: int = 5\n",
        "    ) -> None:\n",
        "        \"\"\"Инициализация модели.\n",
        "\n",
        "        Args:\n",
        "            alphas: Значения регуляризации для перебора.\n",
        "            n_splits: Число фолдов кросс-валидации.\n",
        "        \"\"\"\n",
        "        self.alphas = alphas or [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "        self.n_splits = n_splits\n",
        "        self.best_model_: Optional[Ridge] = None\n",
        "        self.best_alpha_: Optional[float] = None\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        X: Union[pd.DataFrame, np.ndarray],\n",
        "        y: Union[pd.Series, np.ndarray]\n",
        "    ) -> 'RidgeRegressionCV':\n",
        "        \"\"\"Обучение с подбором гиперпараметров.\n",
        "\n",
        "        Args:\n",
        "            X: Матрица признаков.\n",
        "            y: Целевая переменная.\n",
        "\n",
        "        Returns:\n",
        "            self: Обученная модель.\n",
        "        \"\"\"\n",
        "        tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
        "        param_grid = {'alpha': self.alphas}\n",
        "\n",
        "        grid_search = GridSearchCV(\n",
        "            Ridge(),\n",
        "            param_grid,\n",
        "            cv=tscv,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        grid_search.fit(X, y)\n",
        "\n",
        "        self.best_model_ = grid_search.best_estimator_\n",
        "        self.best_alpha_ = grid_search.best_params_['alpha']\n",
        "        return self\n",
        "\n",
        "    def predict(\n",
        "        self,\n",
        "        X: Union[pd.DataFrame, np.ndarray]\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"Предсказание.\n",
        "\n",
        "        Args:\n",
        "            X: Матрица признаков.\n",
        "\n",
        "        Returns:\n",
        "            Предсказанные значения.\n",
        "        \"\"\"\n",
        "        return self.best_model_.predict(X)\n",
        "\n",
        "    def get_params(self, deep: bool = True) -> dict:\n",
        "        \"\"\"Получение параметров для sklearn.\"\"\"\n",
        "        return {'alphas': self.alphas, 'n_splits': self.n_splits}\n",
        "\n",
        "    def set_params(self, **params) -> 'RidgeRegressionCV':\n",
        "        \"\"\"Установка параметров для sklearn.\"\"\"\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "        return self\n",
        "\n",
        "\n",
        "print('RidgeRegressionCV создан')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4z12P307Pwg"
      },
      "source": [
        "## Байесовская линейная модель (PyTorch)\n",
        "\n",
        "Реализуем байесовскую линейную регрессию с глобальными случайными весами и свободным коэффициентом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFWYY-dZG1Q_"
      },
      "outputs": [],
      "source": [
        "class BayesianLinearModel(nn.Module):\n",
        "    \"\"\"Байесовская линейная регрессия с вариационным выводом.\n",
        "\n",
        "    Использует Mean-Field Approximation: q(w) = N(μ, diag(σ²)).\n",
        "\n",
        "    Attributes:\n",
        "        num_features: Размерность входа.\n",
        "        prior_std: СКО априорного распределения весов.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_features: int, prior_std: float = 1.0) -> None:\n",
        "        \"\"\"Инициализация модели.\n",
        "\n",
        "        Args:\n",
        "            num_features: Число входных признаков.\n",
        "            prior_std: Стандартное отклонение априора.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.prior_std = prior_std\n",
        "\n",
        "        # Вариационные параметры весов: μ и ρ (σ = softplus(ρ))\n",
        "        self.mu_w = nn.Parameter(torch.zeros(num_features))\n",
        "        self.rho_w = nn.Parameter(torch.full((num_features,), -3.0))\n",
        "\n",
        "        # Вариационные параметры bias\n",
        "        self.mu_b = nn.Parameter(torch.zeros(1))\n",
        "        self.rho_b = nn.Parameter(torch.tensor(-3.0))\n",
        "\n",
        "        # Шум наблюдений (обучаемый)\n",
        "        self.rho_noise = nn.Parameter(torch.tensor([0.0]))\n",
        "\n",
        "    @property\n",
        "    def sigma_w(self) -> torch.Tensor:\n",
        "        \"\"\"СКО весов: σ = softplus(ρ) + ε.\"\"\"\n",
        "        return F.softplus(self.rho_w) + 1e-6\n",
        "\n",
        "    @property\n",
        "    def sigma_b(self) -> torch.Tensor:\n",
        "        \"\"\"СКО bias.\"\"\"\n",
        "        return F.softplus(self.rho_b) + 1e-6\n",
        "\n",
        "    @property\n",
        "    def noise_std(self) -> torch.Tensor:\n",
        "        \"\"\"СКО шума наблюдений.\"\"\"\n",
        "        return F.softplus(self.rho_noise) + 1e-6\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        X: torch.Tensor,\n",
        "        num_samples: int = 1\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Прямой проход с сэмплированием весов.\n",
        "\n",
        "        Args:\n",
        "            X: Входной тензор (batch_size, num_features).\n",
        "            num_samples: Число сэмплов весов.\n",
        "\n",
        "        Returns:\n",
        "            Предсказания (batch_size, num_samples).\n",
        "        \"\"\"\n",
        "        # Reparameterization trick: w = μ + σ * ε\n",
        "        eps_w = torch.randn(\n",
        "            num_samples, self.num_features, device=X.device\n",
        "        )\n",
        "        w = self.mu_w + self.sigma_w * eps_w\n",
        "\n",
        "        eps_b = torch.randn(num_samples, 1, device=X.device)\n",
        "        b = self.mu_b + self.sigma_b * eps_b\n",
        "\n",
        "        # Линейная регрессия: y = X @ w.T + b\n",
        "        y_pred = F.linear(X, w, b.squeeze(-1))\n",
        "        return y_pred\n",
        "\n",
        "    def kl_divergence(self) -> torch.Tensor:\n",
        "        \"\"\"Аналитический KL(q(w) || p(w)).\n",
        "\n",
        "        Returns:\n",
        "            Значение KL-дивергенции.\n",
        "        \"\"\"\n",
        "        prior_var = self.prior_std ** 2\n",
        "\n",
        "        # KL для весов\n",
        "        kl_w = 0.5 * torch.sum(\n",
        "            (self.sigma_w**2 + self.mu_w**2) / prior_var\n",
        "            - 1\n",
        "            - 2 * torch.log(self.sigma_w / self.prior_std)\n",
        "        )\n",
        "\n",
        "        # KL для bias\n",
        "        kl_b = 0.5 * torch.sum(\n",
        "            (self.sigma_b**2 + self.mu_b**2) / prior_var\n",
        "            - 1\n",
        "            - 2 * torch.log(self.sigma_b / self.prior_std)\n",
        "        )\n",
        "\n",
        "        return kl_w + kl_b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHetB4r57Pwg"
      },
      "source": [
        "## Sklearn-обёртка для SVI\n",
        "\n",
        "Аналогичным образом, обернём байесовскую регрессию в scikit-learn-эстиматор и предиктор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktAmiaTVG1Tq"
      },
      "outputs": [],
      "source": [
        "class BayesianRegressorSVI(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"Байесовская регрессия с Stochastic Variational Inference.\n",
        "\n",
        "    Attributes:\n",
        "        num_epochs: Число эпох обучения.\n",
        "        lr: Скорость обучения.\n",
        "        batch_size: Размер мини-батча.\n",
        "        prior_std: СКО априора.\n",
        "        num_train_samples: MC-сэмплов при обучении.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_epochs: int = 1000,\n",
        "        lr: float = 0.01,\n",
        "        batch_size: int = 64,\n",
        "        prior_std: float = 1.0,\n",
        "        num_train_samples: int = 1,\n",
        "        random_state: Optional[int] = None,\n",
        "        device: str = 'cpu'\n",
        "    ) -> None:\n",
        "        \"\"\"Инициализация модели.\n",
        "\n",
        "        Args:\n",
        "            num_epochs: Количество эпох.\n",
        "            lr: Learning rate.\n",
        "            batch_size: Размер батча.\n",
        "            prior_std: СКО априорного распределения.\n",
        "            num_train_samples: Число сэмплов для оценки ELBO.\n",
        "            random_state: Seed для воспроизводимости.\n",
        "            device: Устройство (cpu/cuda).\n",
        "        \"\"\"\n",
        "        self.num_epochs = num_epochs\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.prior_std = prior_std\n",
        "        self.num_train_samples = num_train_samples\n",
        "        self.random_state = random_state\n",
        "        self.device = device\n",
        "        self.model: Optional[BayesianLinearModel] = None\n",
        "        self.losses: List[float] = []\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        X: Union[pd.DataFrame, np.ndarray],\n",
        "        y: Union[pd.Series, np.ndarray]\n",
        "    ) -> 'BayesianRegressorSVI':\n",
        "        \"\"\"Обучение методом SVI.\n",
        "\n",
        "        Args:\n",
        "            X: Матрица признаков.\n",
        "            y: Целевая переменная.\n",
        "\n",
        "        Returns:\n",
        "            self: Обученная модель.\n",
        "        \"\"\"\n",
        "        if self.random_state:\n",
        "            torch.manual_seed(self.random_state)\n",
        "            np.random.seed(self.random_state)\n",
        "\n",
        "        # Конвертация в тензоры\n",
        "        X_arr = X.values if hasattr(X, 'values') else X\n",
        "        y_arr = y.values if hasattr(y, 'values') else y\n",
        "\n",
        "        X_t = torch.tensor(X_arr, dtype=torch.float32).to(self.device)\n",
        "        y_t = torch.tensor(y_arr, dtype=torch.float32)\n",
        "        y_t = y_t.view(-1).to(self.device)\n",
        "\n",
        "        dataset_size, num_features = X_t.shape\n",
        "\n",
        "        # Инициализация модели\n",
        "        self.model = BayesianLinearModel(\n",
        "            num_features, self.prior_std\n",
        "        ).to(self.device)\n",
        "\n",
        "        # DataLoader для батчей\n",
        "        dataset = TensorDataset(X_t, y_t)\n",
        "        loader = DataLoader(\n",
        "            dataset, batch_size=self.batch_size, shuffle=True\n",
        "        )\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        self.model.train()\n",
        "        self.losses = []\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            epoch_loss = 0.0\n",
        "\n",
        "            for X_batch, y_batch in loader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward: (batch_size, num_samples)\n",
        "                preds = self.model(\n",
        "                    X_batch, num_samples=self.num_train_samples\n",
        "                )\n",
        "\n",
        "                # Log Likelihood\n",
        "                ll_matrix = torch.distributions.Normal(\n",
        "                    preds, self.model.noise_std\n",
        "                ).log_prob(y_batch.view(-1, 1))\n",
        "\n",
        "                # Среднее по сэмплам, сумма по батчу\n",
        "                ll_batch_sum = ll_matrix.mean(dim=1).sum()\n",
        "\n",
        "                # KL с масштабированием по размеру батча\n",
        "                kl = self.model.kl_divergence()\n",
        "                kl_weight = len(X_batch) / dataset_size\n",
        "\n",
        "                # Loss = -ELBO\n",
        "                loss = -ll_batch_sum + kl * kl_weight\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            # Отображаем процесс обучения\n",
        "            print(f\"Epoch: {epoch:3d} | Loss: {epoch_loss:10.4f}\")\n",
        "            self.losses.append(epoch_loss)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(\n",
        "        self,\n",
        "        X: Union[pd.DataFrame, np.ndarray],\n",
        "        num_pred_samples: int = 1,\n",
        "        return_samples: bool = False\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"Предсказание с posterior predictive.\n",
        "\n",
        "        Args:\n",
        "            X: Матрица признаков.\n",
        "            num_pred_samples: Число сэмплов на этапе предсказания.\n",
        "            return_samples: Вернуть все сэмплы или же их среднее.\n",
        "\n",
        "        Returns:\n",
        "            Если return_samples=True: (batch, num_samples).\n",
        "            Иначе: (batch,) — среднее.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        X_arr = X.values if hasattr(X, 'values') else X\n",
        "        X_t = torch.tensor(X_arr, dtype=torch.float32).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Epistemic uncertainty (из весов)\n",
        "            preds = self.model(X_t, num_samples=num_pred_samples)\n",
        "\n",
        "            # Aleatoric uncertainty (шум данных)\n",
        "            noise = torch.randn_like(preds) * self.model.noise_std\n",
        "            preds_with_noise = preds + noise\n",
        "\n",
        "            result = preds_with_noise.cpu().numpy()\n",
        "\n",
        "        if return_samples:\n",
        "            return result\n",
        "\n",
        "        return result.mean(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqIl2ooW7Pwh"
      },
      "source": [
        "## Препроцессор и пайплайны\n",
        "\n",
        "Формируем scikit-learn-конвейер для преобразования признаков и обучения модели.\n",
        "Количественные признаки нуждаются в масштабировании."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmse4VUft1nI"
      },
      "outputs": [],
      "source": [
        "# Препроцессор: масштабирование числовых признаков\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('scaler', StandardScaler(), ['solar_radiation', 'temp_max'])\n",
        "    ],\n",
        "    remainder='passthrough',\n",
        "    verbose_feature_names_out=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqCXdxmgw3I7"
      },
      "outputs": [],
      "source": [
        "# Pipeline для Ridge-регрессии\n",
        "pipeline_ridge = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('lagger', LaggedFeaturesTransformer(n_lags=N_LAGS)),\n",
        "    ('model', RidgeRegressionCV())\n",
        "])\n",
        "pipeline_ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP8Z3SNXw6KM"
      },
      "outputs": [],
      "source": [
        "# Pipeline для байесовской регрессии\n",
        "pipeline_bayesian = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('lagger', LaggedFeaturesTransformer(n_lags=N_LAGS)),\n",
        "    ('model', BayesianRegressorSVI(\n",
        "        num_epochs=400,\n",
        "        lr=0.01,\n",
        "        batch_size=64,\n",
        "        num_train_samples=128\n",
        "    ))\n",
        "])\n",
        "pipeline_bayesian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbQVFCH27Pwh"
      },
      "source": [
        "## Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koJTTZuuwEBl"
      },
      "outputs": [],
      "source": [
        "def lag_label(data: pd.DataFrame, num_lags: int = N_LAGS) -> pd.Series:\n",
        "    \"\"\"Сдвиг целевой переменной для соответствия лаговым признакам.\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame с колонкой temp_max.\n",
        "        num_lags: Число лагов для сдвига.\n",
        "\n",
        "    Returns:\n",
        "        Series с целевой переменной без первых num_lags значений.\n",
        "    \"\"\"\n",
        "    return data.reset_index()['temp_max'][num_lags:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlkAeeh-7Pwi"
      },
      "source": [
        "## Обучение моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziiB5Wnjt1s8"
      },
      "outputs": [],
      "source": [
        "print('Обучение Ridge...')\n",
        "pipeline_ridge.fit(X_train, lag_label(y_train))\n",
        "print(f'  Лучший alpha: {pipeline_ridge.named_steps[\"model\"].best_alpha_}')\n",
        "\n",
        "print('Обучение Bayesian SVI...')\n",
        "pipeline_bayesian.fit(X_train, lag_label(y_train))\n",
        "print('Все модели обучены!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4uW9dDO7Pwi"
      },
      "source": [
        "## Валидация (прямой прогноз)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya70wb9It1vm"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(\n",
        "    name: str,\n",
        "    y_true: np.ndarray,\n",
        "    y_pred: np.ndarray\n",
        ") -> dict:\n",
        "    \"\"\"Вычисление метрик качества.\n",
        "\n",
        "    Args:\n",
        "        name: Название модели.\n",
        "        y_true: Истинные значения.\n",
        "        y_pred: Предсказанные значения.\n",
        "\n",
        "    Returns:\n",
        "        Словарь с метриками RMSE, MAE, R².\n",
        "    \"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {'Model': name, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
        "\n",
        "\n",
        "# Оценка на валидации\n",
        "results_val = []\n",
        "\n",
        "pred_ridge_val = pipeline_ridge.predict(X_val)\n",
        "results_val.append(\n",
        "    evaluate_model('Ridge', lag_label(y_val).to_numpy(), pred_ridge_val)\n",
        ")\n",
        "\n",
        "pred_bayes_val = pipeline_bayesian.predict(X_val)\n",
        "results_val.append(\n",
        "    evaluate_model('Bayesian SVI', lag_label(y_val).to_numpy(), pred_bayes_val)\n",
        ")\n",
        "\n",
        "print('Результаты на валидации (прямой прогноз):')\n",
        "pd.DataFrame(results_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxQxLKPY7Pwi"
      },
      "source": [
        "## Авторегрессионный прогноз\n",
        "\n",
        "Предсказания предыдущих шагов используются как входные признаки.\n",
        "\n",
        "Формируем функции для выполнения авторегрессионного предскажания значений ряда."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGR45T6GmBSS"
      },
      "outputs": [],
      "source": [
        "def autoregressive_forecast_classic_pipeline(\n",
        "    pipeline: Pipeline,\n",
        "    test_data: pd.DataFrame,\n",
        "    num_lags: int,\n",
        "    target_col: str = 'temp_max'\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Авторегрессионный прогноз для классических моделей.\n",
        "\n",
        "    Args:\n",
        "        pipeline: Обученный sklearn pipeline.\n",
        "        test_data: Тестовые данные.\n",
        "        num_lags: Число лагов.\n",
        "        target_col: Имя целевой колонки.\n",
        "\n",
        "    Returns:\n",
        "        Массив предсказаний.\n",
        "    \"\"\"\n",
        "    df_test = test_data.copy().reset_index(drop=True)\n",
        "    df_test[target_col][num_lags:] = np.nan\n",
        "    y_preds = []\n",
        "\n",
        "    for i in range(0, len(df_test.index) - num_lags):\n",
        "        y_pred = pipeline.predict(df_test[i:i + num_lags + 1])\n",
        "        df_test[\"temp_max\"].iloc[i + num_lags] = y_pred\n",
        "        y_preds.append(y_pred)\n",
        "\n",
        "    return np.concatenate(y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdERcAiemBdd"
      },
      "outputs": [],
      "source": [
        "def autoregressive_forecast_bayesian_pipeline(\n",
        "    pipeline: Pipeline,\n",
        "    test_data: pd.DataFrame,\n",
        "    num_lags: int,\n",
        "    num_pred_samples: int = 1024,\n",
        "    target_col: str = 'temp_max'\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Авторегрессионный прогноз для байесовской модели.\n",
        "\n",
        "    Args:\n",
        "        pipeline: Обученный sklearn pipeline.\n",
        "        test_data: Тестовые данные.\n",
        "        num_lags: Число лагов.\n",
        "        num_pred_samples: Число MC-сэмплов для неопределённости.\n",
        "        target_col: Имя целевой колонки.\n",
        "\n",
        "    Returns:\n",
        "        Кортеж (средние предсказания, стандартные отклонения).\n",
        "    \"\"\"\n",
        "    df_test = test_data.copy().reset_index(drop=True)\n",
        "    df_test[target_col][num_lags:] = np.nan\n",
        "    y_preds_mean = []\n",
        "    y_preds_std = []\n",
        "\n",
        "    for i in range(0, len(df_test.index) - num_lags):\n",
        "        y_pred = pipeline.predict(\n",
        "            df_test[i:i + num_lags + 1],\n",
        "            num_pred_samples=num_pred_samples,\n",
        "            return_samples=True\n",
        "        )\n",
        "        y_pred_mean = y_pred.mean(axis=1)\n",
        "        y_pred_std = y_pred.std(axis=1)\n",
        "\n",
        "        df_test[\"temp_max\"].iloc[i + num_lags] = y_pred_mean\n",
        "        y_preds_mean.append(y_pred_mean)\n",
        "        y_preds_std.append(y_pred_std)\n",
        "\n",
        "    return np.concatenate(y_preds_mean), np.concatenate(y_preds_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0eciDcHKo9B"
      },
      "source": [
        "Выполняем авторегрессионное прогнозирование для обеих моделей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rBN0zk9vJHS"
      },
      "outputs": [],
      "source": [
        "# Авторегрессионные прогнозы\n",
        "print('Ridge AR...')\n",
        "pred_ridge_ar = autoregressive_forecast_classic_pipeline(\n",
        "    pipeline_ridge,\n",
        "    X_test,\n",
        "    num_lags=N_LAGS\n",
        ")\n",
        "\n",
        "print('Bayesian SVI AR...')\n",
        "pred_bayes_ar, std_bayes_ar = autoregressive_forecast_bayesian_pipeline(\n",
        "    pipeline_bayesian,\n",
        "    X_test,\n",
        "    num_lags=N_LAGS\n",
        ")\n",
        "\n",
        "print('Авторегрессионные прогнозы получены')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUajsxG7Pwi"
      },
      "source": [
        "## Финальные метрики на тестовых данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UDPLKMovJJ_"
      },
      "outputs": [],
      "source": [
        "# Метрики в авторегрессионном режиме\n",
        "results_test = []\n",
        "results_test.append(\n",
        "    evaluate_model('Ridge (AR)', lag_label(y_test).to_numpy(), pred_ridge_ar)\n",
        ")\n",
        "results_test.append(\n",
        "    evaluate_model(\n",
        "        'Bayesian SVI (AR)', lag_label(y_test).to_numpy(), pred_bayes_ar\n",
        "    )\n",
        ")\n",
        "\n",
        "df_results = pd.DataFrame(results_test)\n",
        "print('Результаты авторегрессионного прогноза на тестовых данных:')\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJBIYSW67Pwi"
      },
      "source": [
        "## Визуализация: временные ряды авторегрессионных предсказаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEnE3MoUx2bs"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=(20, 14))\n",
        "\n",
        "# Ridge AR\n",
        "axes[0].plot(\n",
        "    dates_test[N_LAGS:], lag_label(y_test).to_numpy(),\n",
        "    'k-', linewidth=2, label='Факт'\n",
        ")\n",
        "axes[0].plot(\n",
        "    dates_test[N_LAGS:], pred_ridge_ar,\n",
        "    'b-', linewidth=1.5, alpha=0.8, label='Ridge (AR)'\n",
        ")\n",
        "axes[0].set_ylabel('Температура, °C')\n",
        "axes[0].set_title(\n",
        "    'Ridge-регрессия (авторегрессионный прогноз)', fontsize=14\n",
        ")\n",
        "axes[0].legend(loc='upper right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Bayesian SVI AR с доверительным интервалом\n",
        "axes[1].plot(\n",
        "    dates_test[N_LAGS:], lag_label(y_test).to_numpy(),\n",
        "    'k-', linewidth=2, label='Факт'\n",
        ")\n",
        "axes[1].plot(\n",
        "    dates_test[N_LAGS:], pred_bayes_ar,\n",
        "    'r-', linewidth=1.5, label='Bayesian SVI (AR)'\n",
        ")\n",
        "axes[1].fill_between(\n",
        "    dates_test[N_LAGS:],\n",
        "    pred_bayes_ar - 1.96 * std_bayes_ar,\n",
        "    pred_bayes_ar + 1.96 * std_bayes_ar,\n",
        "    alpha=0.3, color='red', label='95% CI'\n",
        ")\n",
        "axes[1].set_ylabel('Температура, °C')\n",
        "axes[1].set_title(\n",
        "    'Байесовская регрессия SVI (авторегрессионный прогноз)', fontsize=14\n",
        ")\n",
        "axes[1].legend(loc='upper right')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Форматирование дат\n",
        "for ax in axes:\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B4hzYt17Pwj"
      },
      "source": [
        "## Scatter plots: сравнение фактических и прогнозных значений ряда"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6DXN4pZx2bs"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
        "\n",
        "models_data = [\n",
        "    ('Ridge (AR)', pred_ridge_ar, 'blue'),\n",
        "    ('Bayesian SVI (AR)', pred_bayes_ar, 'red')\n",
        "]\n",
        "\n",
        "y_true = lag_label(y_test).to_numpy()\n",
        "\n",
        "for ax, (name, pred, color) in zip(axes, models_data):\n",
        "    ax.scatter(y_true, pred, alpha=0.5, c=color, s=50)\n",
        "\n",
        "    min_val = min(y_true.min(), pred.min())\n",
        "    max_val = max(y_true.max(), pred.max())\n",
        "    ax.plot(\n",
        "        [min_val, max_val], [min_val, max_val],\n",
        "        'k--', linewidth=2, label='Идеальный прогноз'\n",
        "    )\n",
        "\n",
        "    ax.set_xlim(min_val - 1, max_val + 1)\n",
        "    ax.set_ylim(min_val - 1, max_val + 1)\n",
        "\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    mae = mean_absolute_error(y_true, pred)\n",
        "    ax.text(\n",
        "        0.05, 0.95, f'R² = {r2:.4f}\\nMAE = {mae:.2f}°C',\n",
        "        transform=ax.transAxes, fontsize=12, verticalalignment='top',\n",
        "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel('Фактическое значение, °C', fontsize=12)\n",
        "    ax.set_ylabel('Прогноз, °C', fontsize=12)\n",
        "    ax.set_title(f'{name}', fontsize=14)\n",
        "    ax.legend(loc='lower right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxtNBSD47Pwj"
      },
      "source": [
        "## Распределение ошибок моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57ecC3S1x2bs"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
        "\n",
        "y_true = lag_label(y_test).to_numpy()\n",
        "\n",
        "errors_data = [\n",
        "    ('Ridge (AR)', y_true - pred_ridge_ar, 'blue'),\n",
        "    ('Bayesian SVI (AR)', y_true - pred_bayes_ar, 'red')\n",
        "]\n",
        "\n",
        "for ax, (name, errors, color) in zip(axes, errors_data):\n",
        "    ax.hist(errors, bins=30, color=color, alpha=0.7, edgecolor='black')\n",
        "    ax.axvline(x=0, color='black', linestyle='--', linewidth=2)\n",
        "    ax.axvline(\n",
        "        x=errors.mean(), color='darkred', linestyle='-', linewidth=2,\n",
        "        label=f'Среднее = {errors.mean():.2f}'\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel('Ошибка (Факт - Прогноз), °C', fontsize=12)\n",
        "    ax.set_ylabel('Частота', fontsize=12)\n",
        "    ax.set_title(f'{name}', fontsize=14)\n",
        "    ax.legend(loc='upper right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYFuKw-o7Pwn"
      },
      "source": [
        "## Сравнение метрик на тестовых данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ_pmfwYx2bs"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 7))\n",
        "\n",
        "models = ['Ridge\\n(AR)', 'Bayesian SVI\\n(AR)']\n",
        "predictions = [pred_ridge_ar, pred_bayes_ar]\n",
        "y_true = lag_label(y_test).to_numpy()\n",
        "\n",
        "# Расчёт метрик\n",
        "rmse_vals = [\n",
        "    np.sqrt(mean_squared_error(y_true, p)) for p in predictions\n",
        "]\n",
        "mae_vals = [mean_absolute_error(y_true, p) for p in predictions]\n",
        "r2_vals = [r2_score(y_true, p) for p in predictions]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax.bar(x - width, rmse_vals, width, label='RMSE, °C', color='steelblue')\n",
        "bars2 = ax.bar(x, mae_vals, width, label='MAE, °C', color='darkorange')\n",
        "bars3 = ax.bar(x + width, r2_vals, width, label='R²', color='seagreen')\n",
        "\n",
        "ax.set_ylabel('Значение метрики', fontsize=12)\n",
        "ax.set_title(\n",
        "    'Сравнение метрик качества моделей (авторегрессионный прогноз)',\n",
        "    fontsize=14\n",
        ")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, fontsize=11)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Подписи значений над столбцами\n",
        "for bar, val in zip(bars1, rmse_vals):\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
        "        f'{val:.2f}', ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "for bar, val in zip(bars2, mae_vals):\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
        "        f'{val:.2f}', ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "for bar, val in zip(bars3, r2_vals):\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
        "        f'{val:.3f}', ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkPuxH5Wx2bs"
      },
      "source": [
        "## Заключение\n",
        "\n",
        "В данной работе реализованы два подхода к авторегрессионному моделированию:\n",
        "\n",
        "1. **Ridge-регрессия** с подбором гиперпараметров через GridSearchCV и TimeSeriesSplit.\n",
        "\n",
        "2. **Байесовская линейная регрессия со стохастическим вариационным выводом (SVI)** и следующими особенностями:\n",
        "   - Обучение на мини-батчах.\n",
        "   - Трюк репараметризации для градиентов.\n",
        "   - Предсказание через многократное сэмплирование весов из q(w).\n",
        "\n",
        "Все модели работают в **авторегрессионном режиме**: предсказания предыдущих шагов используются как входные признаки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8qZbaCVBdcu"
      },
      "source": [
        "## Индивидуальное задание\n",
        "\n",
        "Опираясь на представленное исследование и используя его в качестве образца, **выполните аналогичные действия с выбранным Вами датасетом**.\n",
        "\n",
        "В процессе работы:\n",
        "\n",
        "1. Выберите датасет, содержащий **временной ряд**. Датасеты можно найти, например, на [Kaggle](https://www.kaggle.com/datasets) и [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). Датасет должен содержать целевую переменную и **хотя бы один** дополнительный признак.\n",
        "\n",
        "2. Выполните **разведочный анализ** датасета: исследуйте временную структуру, сезонность, тренды. Выполните требуемые **преобразования признаков** (масштабирование, бинаризация и др.).\n",
        "\n",
        "3. Разделите датасет на **обучающую**, **валидационную** и **тестовую** части с сохранением временного порядка.\n",
        "\n",
        "4. Реализуйте **трансформер лаговых признаков** для построения авторегрессионной модели заданного порядка $p$.\n",
        "\n",
        "5. Реализуйте **Ridge-регрессию** с автоматическим подбором коэффициента регуляризации через кросс-валидацию по временным рядам (TimeSeriesSplit).\n",
        "\n",
        "6. Составьте **байесовскую линейную модель** для решения задачи регрессии. Запишите априорные распределения весов, правдоподобие и вид апостериорного распределения.\n",
        "\n",
        "7. Реализуйте байесовскую модель на **PyTorch** с использованием **стохастического вариационного вывода (SVI)**. Используйте Mean-Field приближение и трюк репараметризации.\n",
        "\n",
        "8. **Обучите** обе модели. Для байесовской модели визуализируйте значения ELBO в процессе обучения.\n",
        "\n",
        "9. Разработайте процедуру **авторегрессионного прогнозирования** для обеих моделей: предсказания предыдущих шагов должны использоваться как входные признаки для следующих.\n",
        "\n",
        "10. **Визуализируйте** прогнозы обеих моделей на тестовой выборке. Для байесовской модели отобразите **доверительные интервалы** (95% CI).\n",
        "\n",
        "11. **Вычислите метрики качества** (RMSE, MAE, R²) для обеих моделей в авторегрессионном режиме. Критически оцените полученные результаты.\n",
        "\n",
        "12. Постройте **scatter-диаграммы** «факт и прогноз» и **гистограммы ошибок** для обеих моделей.\n",
        "\n",
        "13. Проведите **сравнительный анализ** частотного и байесовского подходов: точность, качество оценки неопределённости, вычислительная сложность.\n",
        "\n",
        "14. Сделайте **выводы** по работе.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2B7PyziTM5Q"
      },
      "source": [
        "## Вопросы для подготовки к отчёту\n",
        "\n",
        "1. Основные понятия теории вероятностей: плотность распределения, правило нормировки, совместная плотность вероятности, математическое ожидание, дисперсия, условная плотность вероятности. Условная независимость.\n",
        "\n",
        "2. Обращение условного распределения. Теорема Байеса и роль каждого из её компонентов в байесовском моделировании.\n",
        "\n",
        "3. Понятие графических вероятностных моделей. Представление вероятностных отношений в виде графа. Байесовская сеть. Наблюдаемые и латентные величины, их обозначения в графических моделях. Нотация «планок» в графических моделях. Глобальные и локальные латентные переменные. Примеры.\n",
        "\n",
        "4. Классический и байесовский подходы к машинному обучению, их сравнительный анализ. Пример линейной регрессии с точки зрения обоих подходов. Постановка задачи и основная проблема байесовского вывода, способы её решения.\n",
        "\n",
        "5. Понятие сэмплирования случайной величины. Способы сэмплирования. Теорема об обратной функции распределения и её применение для сэмплирования. Сэмплирование с отклонением (Rejection sampling). Сэмплирование по важности (Importance sampling). Forward sampling.\n",
        "\n",
        "6. Вариационный инференс как метод решения задачи байесовского вывода. Идея вариационного инференса. Дивергенция Кульбака-Лейблера в задаче вариационного инференса. Вариационная нижняя оценка правдоподобия данных.\n",
        "\n",
        "7. Вариационный инференс как оптимизационная задача. Стохастический вариационный инференс. Проблема расчёта градиента от оценки математического ожидания. Трюк репараметризации. Пример для нормального распределения.\n",
        "\n",
        "8. Амортизированный вариационный инференс: назначение, сущность и особенности.  Отличие амортизированного инференса от классического вариационного вывода. Понятие Inference Network, примеры архитектур.\n",
        "\n",
        "9. Понятие байесовских нейронных сетей. Отличие от классических нейронных сетей. Построение байесовской нейронной сети. Виды неопределённости: эпистемическая и алеаторическая.\n",
        "\n",
        "10. Авторегрессионные модели: определение, структура, область применения. Авторегрессионная модель порядка $p$. Выражение для факторизации совместного распределения переменных временного ряда, порождаемого AR-моделью.  Авторегрессионное прогнозирование, накопление ошибки и неопределённости при многошаговом прогнозе.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC5HVjXoJd2v"
      },
      "source": [
        "## Список рекомендуемой литературы\n",
        "\n",
        "1. Дауни, А. Б. Байесовские модели / А. Б. Дауни ; перевод с английского В. А. Яроцкого. — Москва : ДМК Пресс, 2018. — 182 с. URL: https://e.lanbook.com/book/131695 (дата обращения: 13.02.2024). — Режим доступа: для авториз. пользователей.\n",
        "\n",
        "2. Barber, D. Bayesian Reasoning and Machine Learning / D. Barber // Cambridge University Press, 2012. URL: [http://www0.cs.ucl.ac.uk/staff/d.barber/brml/](http://www0.cs.ucl.ac.uk/staff/d.barber/brml/) (дата обращения: 13.02.2024).\n",
        "\n",
        "3. Bishop, M.C. Pattern Recognition and Machine Learning / M.C. Bishop // Springer, 2006. — 738 с. URL: [https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) (дата обращения: 13.02.2024).\n",
        "\n",
        "4. Hoffman M., Blei D. M, Wang C., Paisley J. Stochastic Variational Inference [Электронный ресурс] // arXiv.org. 2013. Дата обновления: 22.04.2013. URL: https://arxiv.org/abs/1206.7051 (дата обращения: 22.05.2024).\n",
        "\n",
        "5. Ranganath R., Gerrish S., Blei D.M. Black Box Variational Inference [Электронный ресурс] // arXiv.org. 2013. Дата обновления: 31.12.2013. URL: https://arxiv.org/pdf/1401.0118 (дата обращения: 22.05.2024).\n",
        "\n",
        "6. Ganguly A., Jain S., Watchareeruetai U. Amortized Variational Inference: A Systematic Review [Электронный ресурс] // arXiv.org. 2023. Дата обновления: 24.10.2013. URL: https://arxiv.org/pdf/2209.10888\n",
        "\n",
        "7. Box G. E. P., Jenkins G. M., Reinsel G. C. Time Series Analysis: Forecasting and Control. — 4th ed. — Wiley, 2015. — 720 с."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
